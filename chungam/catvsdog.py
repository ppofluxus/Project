# -*- coding: utf-8 -*-
"""Untitled2.ipynb의 사본

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SXbgdW5_QEEQRhvNKI_TLYbgxyAJSniX
"""

import tensorflow as tf
from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, UpSampling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.utils.class_weight import compute_class_weight
import csv
from datetime import datetime
import numpy as np
import os
import matplotlib.pyplot as plt
import json

# 로컬 실행용: Colab 전용 코드 제거 및 로컬 데이터 경로 설정
# 학습 데이터 디렉토리: 내부에 'Cat' / 'Dog' 하위 폴더가 존재해야 합니다.
data_dir = '/Users/ppofluxus/Documents/Project/chungam/cat and dog'

# 경로 유효성 검사 (공백 포함 경로 안전 처리)
if not os.path.isdir(data_dir):
    raise FileNotFoundError(
        f"데이터 디렉토리를 찾을 수 없습니다: {data_dir}\n"
        "경로가 올바른지와 'Cat' / 'Dog' 폴더가 내부에 있는지 확인하세요."
    )

# 간단한 이미지 존재 여부 점검
def _count_images(root: str) -> int:
    exts = {'.jpg', '.jpeg', '.png', '.bmp', '.ppm', '.tif', '.tiff'}
    total = 0
    for sub in ('Cat', 'Dog'):
        subdir = os.path.join(root, sub)
        if not os.path.isdir(subdir):
            continue
        for fn in os.listdir(subdir):
            _, ext = os.path.splitext(fn)
            if ext.lower() in exts:
                total += 1
    return total

num_images = _count_images(data_dir)
if num_images == 0:
    raise SystemExit(
        "데이터 폴더를 찾았지만 이미지가 없습니다.\n"
        "아래 구조로 이미지를 배치해 주세요:\n"
        f"  {data_dir}/Cat/*.jpg(png,...)\n"
        f"  {data_dir}/Dog/*.jpg(png,...)\n"
        "또는 배치 크기를 줄이거나 샘플 이미지를 몇 장이라도 추가한 뒤 다시 실행하세요."
    )

# 이미지 데이터 로드 및 전처리
image_size = (128, 128)
batch_size = 32

# 데이터 증강 및 전처리 설정
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2  # 훈련 데이터의 20%를 검증 데이터로 사용
)

# 훈련 데이터 로드
train_generator = datagen.flow_from_directory(
    data_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='binary', # 이진 분류 (강아지 또는 고양이)
    subset='training'
)

# 검증 데이터 로드
validation_generator = datagen.flow_from_directory(
    data_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='binary', # 이진 분류 (강아지 또는 고양이)
    subset='validation',
    shuffle=False # 검증 평가지표 산출을 위해 순서 고정
)

print("데이터 로드 및 전처리 완료.")

# 클래스 불균형 대응 옵션 설정
FOCAL_LOSS = os.getenv('FOCAL_LOSS', '0').lower() in ('1','true','yes','y')
FOCAL_ALPHA = float(os.getenv('FOCAL_ALPHA', '0.25'))
FOCAL_GAMMA = float(os.getenv('FOCAL_GAMMA', '2.0'))
CLASS_WEIGHT_MODE = os.getenv('CLASS_WEIGHT', 'auto').lower()  # 'auto' | 'none'

# Fine-tuning 및 특징 추출/클러스터링 설정
FINETUNE_EPOCHS = int(os.getenv('FINETUNE_EPOCHS', '5'))
FINETUNE_LR = float(os.getenv('FINETUNE_LR', '1e-4'))
UNFREEZE_LAST = int(os.getenv('UNFREEZE_LAST', '50'))  # 마지막 N개 층 미동결
FEATURE_LAYER = os.getenv('FEATURE_LAYER', 'avg_pool')  # 예: 'conv5_block3_out' 또는 'avg_pool'
KMEANS_N_INIT = int(os.getenv('KMEANS_N_INIT', '20'))
KMEANS_MAX_ITER = int(os.getenv('KMEANS_MAX_ITER', '300'))

def binary_focal_loss(alpha: float = 0.25, gamma: float = 2.0):
    def loss(y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.cast(y_pred, tf.float32)
        eps = tf.keras.backend.epsilon()
        y_pred = tf.clip_by_value(y_pred, eps, 1. - eps)
        # BCE per-sample
        bce = -(y_true * tf.math.log(y_pred) + (1. - y_true) * tf.math.log(1. - y_pred))
        p_t = tf.where(tf.equal(y_true, 1.), y_pred, 1. - y_pred)
        alpha_factor = tf.where(tf.equal(y_true, 1.), alpha, 1. - alpha)
        modulating = tf.pow(1. - p_t, gamma)
        return tf.reduce_mean(alpha_factor * modulating * bce)
    return loss

# CNN 모델 정의
cnn_model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid') # 이진 분류를 위해 sigmoid 사용
])

# 모델 컴파일
loss_fn = binary_focal_loss(FOCAL_ALPHA, FOCAL_GAMMA) if FOCAL_LOSS else 'binary_crossentropy'
cnn_model.compile(optimizer='adam',
                  loss=loss_fn, # 이진 분류 손실 함수
                  metrics=['accuracy'])

print("CNN 모델 정의 및 컴파일 완료.")
cnn_model.summary()

# 학습용 클래스 가중치 계산 (옵션)
class_weight_dict = None
try:
    if CLASS_WEIGHT_MODE != 'none':
        classes_array = train_generator.classes
        unique_classes = sorted(set(classes_array.tolist()))
        counts = {int(c): int(np.sum(classes_array == c)) for c in unique_classes}
        print(f"학습 데이터 클래스 분포: {counts}")
        classes = np.array(unique_classes)
        weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_generator.classes)
        class_weight_dict = {int(c): float(w) for c, w in zip(classes, weights)}
        print(f"클래스 가중치 적용: {class_weight_dict}")
    else:
        print("클래스 가중치 미적용 (CLASS_WEIGHT=none)")
except Exception as e:
    print(f"[경고] 클래스 가중치 계산 실패: {e}")

# 모델 학습
# ImageDataGenerator를 사용하므로 fit_generator 또는 generator 인자를 사용합니다.
# TensorFlow 2.1 이상에서는 fit 메서드에 generator를 전달하는 것이 권장됩니다.

history = cnn_model.fit(
    train_generator,
    epochs=20, # 주어진 에포크 수 유지
    validation_data=validation_generator,
    class_weight=class_weight_dict
)

print("CNN 모델 학습 완료.")

# CNN 결과 요약/평가 출력 및 CSV 기록
try:
    class_map = validation_generator.class_indices
    idx2name = {v: k for k, v in class_map.items()}
    target_names = [idx2name[i] for i in sorted(idx2name.keys())]

    # 학습 곡선 요약
    train_acc_hist = history.history.get('accuracy', [])
    val_acc_hist = history.history.get('val_accuracy', [])
    train_loss_hist = history.history.get('loss', [])
    val_loss_hist = history.history.get('val_loss', [])
    best_val_acc = max(val_acc_hist) if val_acc_hist else None
    best_epoch = (val_acc_hist.index(best_val_acc) + 1) if val_acc_hist else None

    # 검증 데이터 예측 및 지표
    validation_generator.reset()
    y_true = validation_generator.classes
    y_prob = cnn_model.predict(validation_generator, verbose=0)
    y_pred = (y_prob.ravel() >= 0.5).astype(int)

    acc = accuracy_score(y_true, y_pred)
    cm = confusion_matrix(y_true, y_pred)
    report = classification_report(y_true, y_pred, target_names=target_names, digits=4)

    print("\n===== CNN 결과 요약 =====")
    if best_val_acc is not None:
        print(f"베스트 Val Acc: {best_val_acc:.4f} (에포크 {best_epoch})")
    if train_acc_hist:
        print(f"최종 Train Acc: {train_acc_hist[-1]:.4f}")
    if val_acc_hist:
        print(f"최종 Val Acc: {val_acc_hist[-1]:.4f}")
    if train_loss_hist:
        print(f"최종 Train Loss: {train_loss_hist[-1]:.4f}")
    if val_loss_hist:
        print(f"최종 Val Loss: {val_loss_hist[-1]:.4f}")

    print("\n- 검증 Accuracy:", f"{acc:.4f}")
    print("- 분류 리포트:\n" + report)
    print("- 혼동행렬:\n", cm)

    # 결과 CSV 기록
    results_path = os.path.join(os.path.dirname(__file__), 'results_cnn.csv')
    header = [
        'timestamp','model','epochs','params','final_train_acc','final_val_acc',
        'final_train_loss','final_val_loss','best_val_acc','best_epoch','val_accuracy_eval',
        'loss','class_weight'
    ]
    row = [
        datetime.now().isoformat(timespec='seconds'),
        'CNN',
        len(train_loss_hist) if train_loss_hist else 0,
        cnn_model.count_params(),
        train_acc_hist[-1] if train_acc_hist else None,
        val_acc_hist[-1] if val_acc_hist else None,
        train_loss_hist[-1] if train_loss_hist else None,
        val_loss_hist[-1] if val_loss_hist else None,
        best_val_acc,
        best_epoch,
        acc,
        f"focal(alpha={FOCAL_ALPHA},gamma={FOCAL_GAMMA})" if FOCAL_LOSS else 'binary_crossentropy',
        json.dumps(class_weight_dict) if class_weight_dict is not None else None,
    ]
    write_header = not os.path.exists(results_path)
    with open(results_path, 'a', newline='') as f:
        w = csv.writer(f)
        if write_header:
            w.writerow(header)
        w.writerow(row)
    print(f"CSV 저장: {results_path}")
except Exception as e:
    print(f"[경고] CNN 결과 요약 중 예외 발생: {e}")

from keras.applications import VGG16
from keras.models import Model

# 1. 사전 학습 모델 로드 (ImageNet 가중치 사용, 최상단 분류 층 제외)
# input_shape는 데이터 전처리 시 설정한 이미지 크기와 채널 수에 맞춥니다.
# Pooling='avg'를 사용하여 마지막 컨볼루션 레이어의 출력을 평균 풀링하여 특징 벡터를 얻습니다.
# include_top=False는 최상단 분류 층을 제외합니다.
base_model_unsupervised = VGG16(weights='imagenet', include_top=False, pooling='avg', input_shape=(image_size[0], image_size[1], 3))

print("사전 학습 모델 로드 완료 (비지도 학습용).")
base_model_unsupervised.summary()

# 2. 특징 추출 모델 정의
# 사전 학습 모델 자체가 특징 추출기 역할을 합니다.
# 여기서는 명확성을 위해 base_model_unsupervised를 feature_extractor_model로 할당합니다.
feature_extractor_model = base_model_unsupervised

print("특징 추출 모델 정의 완료.")
feature_extractor_model.summary()

# 3. 데이터 준비
# 특징 추출에 사용할 이미지 데이터를 준비합니다. 이때, 레이블은 특징 추출 단계에서는 직접적으로 사용되지 않습니다.
# 기존에 생성된 train_generator를 사용하여 이미지 데이터를 로드합니다.

# 데이터 제너레이터에서 이미지 데이터 추출 (특징 추출에 사용할 데이터)
# 모든 데이터를 한 번에 메모리에 올릴 수 있도록 steps를 total_samples // batch_size로 설정합니다.
# 이진 분류이므로 train_generator.class_indices를 사용하여 클래스 인덱스를 얻습니다.
train_images_list = []
train_labels_list = [] # 레이블은 특징 추출 자체에는 필요 없지만, 나중에 클러스터링 평가에 사용될 수 있습니다.
train_generator.reset() # 제너레이터 초기화

print("특징 추출을 위한 훈련 데이터 로드 중...")

for i in range(train_generator.samples // batch_size):
    images, labels = next(train_generator)
    train_images_list.append(images)
    train_labels_list.append(labels)

# 남은 데이터 (마지막 배치) 처리
if train_generator.samples % batch_size != 0:
     images, labels = next(train_generator)
     train_images_list.append(images)
     train_labels_list.append(labels)


train_images_all = np.concatenate(train_images_list)
train_labels_all = np.concatenate(train_labels_list) # 나중에 클러스터링 평가를 위해 저장

print("훈련 데이터 로드 완료.")
print(f"로드된 이미지 데이터 형태: {train_images_all.shape}")
print(f"로드된 레이블 데이터 형태: {train_labels_all.shape}")

# 4. 이미지 특징 추출
# 정의된 특징 추출 모델 (사전 학습된 VGG16의 특징 추출 부분)을 사용하여 준비된 이미지 데이터로부터 특징 벡터를 추출합니다.

print("이미지 특징 추출 중...")
# feature_extractor_model은 VGG16 base_model_unsupervised와 동일합니다.
# train_images_all은 3단계에서 로드한 전체 훈련 이미지 데이터입니다.
encoded_features_unsupervised = feature_extractor_model.predict(train_images_all)
print("이미지 특징 추출 완료.")
print(f"추출된 특징 벡터 형태: {encoded_features_unsupervised.shape}")

# K-Means는 2차원 입력을 기대하므로, 추출된 특징 벡터를 Flatten합니다.
# Pooling='avg'를 사용했기 때문에 이미 1차원 형태일 가능성이 높지만, 안전하게 reshape합니다.
if len(encoded_features_unsupervised.shape) > 2:
    encoded_features_unsupervised_flat = encoded_features_unsupervised.reshape(encoded_features_unsupervised.shape[0], -1)
else:
    encoded_features_unsupervised_flat = encoded_features_unsupervised


print(f"K-Means를 위한 Flatten된 특징 벡터 형태: {encoded_features_unsupervised_flat.shape}")

# 5. K-Means 클러스터링 적용
# 추출된 특징 벡터에 K-Means 클러스터링 알고리즘을 적용하여 이미지를 그룹화합니다.
# 클러스터 수는 데이터셋의 실제 클래스 수에 맞춥니다 (강아지, 고양이 = 2개).

n_clusters = 2
kmeans_unsupervised = KMeans(n_clusters=n_clusters, random_state=42, init='k-means++', n_init=KMEANS_N_INIT, max_iter=KMEANS_MAX_ITER)
print(f"K-Means 클러스터링 수행 중 ({n_clusters}개 클러스터)...")

# K-Means는 2차원 입력을 기대하므로, 추출된 특징 벡터를 Flatten된 형태로 사용합니다.
# encoded_features_unsupervised_flat는 4단계에서 준비했습니다.
kmeans_labels_unsupervised = kmeans_unsupervised.fit_predict(encoded_features_unsupervised_flat)

print("K-Means 클러스터링 완료.")
print(f"생성된 클러스터 레이블 형태: {kmeans_labels_unsupervised.shape}")

# 6. 클러스터링 결과 평가
# 실제 레이블이 있는 경우, Adjusted Rand Index (ARI), Normalized Mutual Information (NMI) 등
# 비지도 학습 평가 지표를 사용하여 클러스터링 결과를 평가합니다.

from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, homogeneity_score, completeness_score, v_measure_score, fowlkes_mallows_score

# 실제 레이블 (train_labels_all)과 KMeans 클러스터 레이블 (kmeans_labels_unsupervised) 비교
# train_labels_all은 3단계에서 로드했습니다.
# kmeans_labels_unsupervised는 5단계에서 생성했습니다.

print("\n--- 전이 학습 기반 K-Means 클러스터링 평가 결과 (실제 레이블과 비교) ---")

# Adjusted Rand Index (ARI) 계산
ari_unsupervised = adjusted_rand_score(train_labels_all, kmeans_labels_unsupervised)
print(f"Adjusted Rand Index (ARI): {ari_unsupervised:.4f}")

# Normalized Mutual Information (NMI) 계산
nmi_unsupervised = normalized_mutual_info_score(train_labels_all, kmeans_labels_unsupervised)
print(f"Normalized Mutual Information (NMI): {nmi_unsupervised:.4f}")

# Homogeneity, Completeness, V-measure 계산
homogeneity = homogeneity_score(train_labels_all, kmeans_labels_unsupervised)
completeness = completeness_score(train_labels_all, kmeans_labels_unsupervised)
v_measure = v_measure_score(train_labels_all, kmeans_labels_unsupervised)
print(f"Homogeneity: {homogeneity:.4f}")
print(f"Completeness: {completeness:.4f}")
print(f"V-measure: {v_measure:.4f}")

# Fowlkes-Mallows Score 계산
fowlkes_mallows = fowlkes_mallows_score(train_labels_all, kmeans_labels_unsupervised)
print(f"Fowlkes-Mallows Score: {fowlkes_mallows:.4f}")

print("\nK-Means 클러스터링 결과와 실제 클래스 분포 확인 (참고):")
# 실제 클래스 레이블 가져오기 (ImageDataGenerator의 class_indices 사용)
# train_generator.class_indices는 {'Cat': 0, 'Dog': 1} 또는 그 반대 형태입니다.
class_labels = list(train_generator.class_indices.keys())
print(f"클래스 레이블: {class_labels}") # 예: ['Cat', 'Dog']

# KMeans 클러스터 0이 실제 어떤 클래스에 더 많이 해당하는지 확인
class_counts_in_cluster_0_unsupervised = {label: 0 for label in class_labels}
for i in range(len(kmeans_labels_unsupervised)):
    if kmeans_labels_unsupervised[i] == 0:
        actual_label_index = int(train_labels_all[i]) # 바이너리 클래스 모드 가정
        actual_label_name = class_labels[actual_label_index]
        class_counts_in_cluster_0_unsupervised[actual_label_name] += 1

print(f"K-Means 클러스터 0에 속한 이미지의 실제 클래스 분포: {class_counts_in_cluster_0_unsupervised}")

# KMeans 클러스터 1이 실제 어떤 클래스에 더 많이 해당하는지 확인
class_counts_in_cluster_1_unsupervised = {label: 0 for label in class_labels}
for i in range(len(kmeans_labels_unsupervised)):
    if kmeans_labels_unsupervised[i] == 1:
        actual_label_index = int(train_labels_all[i])
        actual_label_name = class_labels[actual_label_index]
        class_counts_in_cluster_1_unsupervised[actual_label_name] += 1

print(f"K-Means 클러스터 1에 속한 이미지의 실제 클래스 분포: {class_counts_in_cluster_1_unsupervised}")

# CNN 모델 평가
loss, accuracy = cnn_model.evaluate(validation_generator)

print(f"CNN 모델 검증 데이터 손실 (Loss): {loss:.4f}")
print(f"CNN 모델 검증 데이터 정확도 (Accuracy): {accuracy:.4f}")

from keras.applications import ResNet50
from keras.models import Model
from keras.layers import Dense, Flatten, Dropout
from keras.optimizers import Adam

# 1. 사전 학습 모델 로드 (ResNet50, ImageNet 가중치 사용, 최상단 분류 층 제외)
# input_shape는 데이터 전처리 시 설정한 이미지 크기와 채널 수에 맞춥니다.
# pooling='avg'를 사용하여 특징 벡터를 얻습니다.
base_model_resnet = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(image_size[0], image_size[1], 3))

print("사전 학습 모델 로드 완료 (ResNet50).")
base_model_resnet.summary()

# 2. 새로운 모델 정의 (사전 학습 모델 위에 새로운 분류 층 추가)
x = base_model_resnet.output
# x = Flatten()(x) # ResNet50 with pooling='avg' is already flattened
x = Dense(256, activation='relu')(x) # 새로운 완전 연결 층 (뉴런 수 증가)
x = Dropout(0.5)(x) # 과적합 방지를 위한 Dropout 층 추가
predictions = Dense(1, activation='sigmoid')(x) # 이진 분류를 위한 출력 층

# 새로운 모델 생성
transfer_model_resnet = Model(inputs=base_model_resnet.input, outputs=predictions)

print("사전 학습 모델 위에 새로운 모델 정의 완료 (ResNet50).")
transfer_model_resnet.summary()

# 3. 사전 학습 모델 층 동결
# ResNet50 기본 모델의 모든 층을 동결하여 학습 중 가중치가 업데이트되지 않도록 합니다.
for layer in base_model_resnet.layers:
    layer.trainable = False

print("사전 학습 모델 층 동결 완료 (ResNet50).")

# 4. 새로운 모델 컴파일
# 동결된 층과 새로 추가된 층을 포함하는 모델을 컴파일합니다.
# 초기 학습을 위해 낮은 학습률을 사용합니다.
optimizer_resnet = Adam(learning_rate=0.001) # 초기 학습률 설정
transfer_model_resnet.compile(optimizer=optimizer_resnet,
                              loss=(binary_focal_loss(FOCAL_ALPHA, FOCAL_GAMMA) if FOCAL_LOSS else 'binary_crossentropy'),
                              metrics=['accuracy'])

print("새로운 모델 컴파일 완료 (ResNet50).")

# 5. 새로운 모델 학습 (전이 학습 - ResNet50)
# 새로 추가된 분류 층만 학습됩니다.
# 데이터 제너레이터는 기존 train_generator와 validation_generator를 사용합니다.

initial_resnet_epochs = 10 # 새로 추가된 층 학습을 위한 에포크 수 (조절 가능)

transfer_history_resnet = transfer_model_resnet.fit(
    train_generator,
    epochs=initial_resnet_epochs,
    validation_data=validation_generator,
    class_weight=class_weight_dict
)

print("새로운 모델 학습 (전이 학습 - ResNet50) 완료.")

# ResNet50 전이학습 결과 요약/평가 출력 및 CSV 기록
try:
    validation_generator.reset()
    y_true_res = validation_generator.classes
    y_prob_res = transfer_model_resnet.predict(validation_generator, verbose=0)
    y_pred_res = (y_prob_res.ravel() >= 0.5).astype(int)

    train_acc_hist_res = transfer_history_resnet.history.get('accuracy', [])
    val_acc_hist_res = transfer_history_resnet.history.get('val_accuracy', [])
    train_loss_hist_res = transfer_history_resnet.history.get('loss', [])
    val_loss_hist_res = transfer_history_resnet.history.get('val_loss', [])
    best_val_acc_res = max(val_acc_hist_res) if val_acc_hist_res else None
    best_epoch_res = (val_acc_hist_res.index(best_val_acc_res) + 1) if val_acc_hist_res else None

    acc_res = accuracy_score(y_true_res, y_pred_res)
    report_res = classification_report(y_true_res, y_pred_res, target_names=target_names, digits=4)
    cm_res = confusion_matrix(y_true_res, y_pred_res)

    print("\n===== ResNet50(TL) 결과 요약 =====")
    if best_val_acc_res is not None:
        print(f"베스트 Val Acc: {best_val_acc_res:.4f} (에포크 {best_epoch_res})")
    if train_acc_hist_res:
        print(f"최종 Train Acc: {train_acc_hist_res[-1]:.4f}")
    if val_acc_hist_res:
        print(f"최종 Val Acc: {val_acc_hist_res[-1]:.4f}")
    if train_loss_hist_res:
        print(f"최종 Train Loss: {train_loss_hist_res[-1]:.4f}")
    if val_loss_hist_res:
        print(f"최종 Val Loss: {val_loss_hist_res[-1]:.4f}")

    print("\n- 검증 Accuracy:", f"{acc_res:.4f}")
    print("- 분류 리포트:\n" + report_res)
    print("- 혼동행렬:\n", cm_res)

    # 결과 CSV 추가 기록
    results_path = os.path.join(os.path.dirname(__file__), 'results_cnn.csv')
    header = [
        'timestamp','model','epochs','params','final_train_acc','final_val_acc',
        'final_train_loss','final_val_loss','best_val_acc','best_epoch','val_accuracy_eval',
        'loss','class_weight'
    ]
    row = [
        datetime.now().isoformat(timespec='seconds'),
        'ResNet50_TL',
        len(train_loss_hist_res) if train_loss_hist_res else 0,
        transfer_model_resnet.count_params(),
        train_acc_hist_res[-1] if train_acc_hist_res else None,
        val_acc_hist_res[-1] if val_acc_hist_res else None,
        train_loss_hist_res[-1] if train_loss_hist_res else None,
        val_loss_hist_res[-1] if val_loss_hist_res else None,
        best_val_acc_res,
        best_epoch_res,
        acc_res,
        f"focal(alpha={FOCAL_ALPHA},gamma={FOCAL_GAMMA})" if FOCAL_LOSS else 'binary_crossentropy',
        json.dumps(class_weight_dict) if class_weight_dict is not None else None,
    ]
    write_header = not os.path.exists(results_path)
    with open(results_path, 'a', newline='') as f:
        w = csv.writer(f)
        if write_header:
            w.writerow(header)
        w.writerow(row)
    print(f"CSV 저장: {results_path}")
except Exception as e:
    print(f"[경고] ResNet50 결과 요약 중 예외 발생: {e}")

# 5-1. 미세조정(Fine-tuning) 단계: ResNet50의 마지막 일부 층을 해제하고 저학습률로 추가 학습
if FINETUNE_EPOCHS > 0:
    try:
        total_layers = len(base_model_resnet.layers)
        unfreeze_from = max(0, total_layers - UNFREEZE_LAST)
        for i, layer in enumerate(base_model_resnet.layers):
            layer.trainable = (i >= unfreeze_from)
        print(f"Fine-tuning: 총 {total_layers}개 층 중 마지막 {UNFREEZE_LAST}개 층(index >= {unfreeze_from})을 학습 가능하게 설정")

        optimizer_ft = Adam(learning_rate=FINETUNE_LR)
        transfer_model_resnet.compile(
            optimizer=optimizer_ft,
            loss=(binary_focal_loss(FOCAL_ALPHA, FOCAL_GAMMA) if FOCAL_LOSS else 'binary_crossentropy'),
            metrics=['accuracy']
        )

        ft_history = transfer_model_resnet.fit(
            train_generator,
            epochs=FINETUNE_EPOCHS,
            validation_data=validation_generator,
            class_weight=class_weight_dict
        )
        print("Fine-tuning 완료 (ResNet50).")

        # Fine-tuning 결과 요약 및 CSV 기록
        try:
            validation_generator.reset()
            y_true_ft = validation_generator.classes
            y_prob_ft = transfer_model_resnet.predict(validation_generator, verbose=0)
            y_pred_ft = (y_prob_ft.ravel() >= 0.5).astype(int)

            train_acc_hist_ft = ft_history.history.get('accuracy', [])
            val_acc_hist_ft = ft_history.history.get('val_accuracy', [])
            train_loss_hist_ft = ft_history.history.get('loss', [])
            val_loss_hist_ft = ft_history.history.get('val_loss', [])
            best_val_acc_ft = max(val_acc_hist_ft) if val_acc_hist_ft else None
            best_epoch_ft = (val_acc_hist_ft.index(best_val_acc_ft) + 1) if val_acc_hist_ft else None

            acc_ft = accuracy_score(y_true_ft, y_pred_ft)
            print("\n===== ResNet50 Fine-tuning 결과 요약 =====")
            if best_val_acc_ft is not None:
                print(f"베스트 Val Acc: {best_val_acc_ft:.4f} (에포크 {best_epoch_ft})")
            if train_acc_hist_ft:
                print(f"최종 Train Acc: {train_acc_hist_ft[-1]:.4f}")
            if val_acc_hist_ft:
                print(f"최종 Val Acc: {val_acc_hist_ft[-1]:.4f}")
            if train_loss_hist_ft:
                print(f"최종 Train Loss: {train_loss_hist_ft[-1]:.4f}")
            if val_loss_hist_ft:
                print(f"최종 Val Loss: {val_loss_hist_ft[-1]:.4f}")
            print("- 검증 Accuracy:", f"{acc_ft:.4f}")

            results_path = os.path.join(os.path.dirname(__file__), 'results_cnn.csv')
            header = [
                'timestamp','model','epochs','params','final_train_acc','final_val_acc',
                'final_train_loss','final_val_loss','best_val_acc','best_epoch','val_accuracy_eval',
                'loss','class_weight'
            ]
            row = [
                datetime.now().isoformat(timespec='seconds'),
                'ResNet50_TL_FT',
                len(train_loss_hist_ft) if train_loss_hist_ft else 0,
                transfer_model_resnet.count_params(),
                train_acc_hist_ft[-1] if train_acc_hist_ft else None,
                val_acc_hist_ft[-1] if val_acc_hist_ft else None,
                train_loss_hist_ft[-1] if train_loss_hist_ft else None,
                val_loss_hist_ft[-1] if val_loss_hist_ft else None,
                best_val_acc_ft,
                best_epoch_ft,
                acc_ft,
                f"focal(alpha={FOCAL_ALPHA},gamma={FOCAL_GAMMA})" if FOCAL_LOSS else 'binary_crossentropy',
                json.dumps(class_weight_dict) if class_weight_dict is not None else None,
            ]
            write_header = not os.path.exists(results_path)
            with open(results_path, 'a', newline='') as f:
                w = csv.writer(f)
                if write_header:
                    w.writerow(header)
                w.writerow(row)
            print(f"CSV 저장: {results_path}")
        except Exception as e:
            print(f"[경고] Fine-tuning 결과 요약 중 예외 발생: {e}")
    except Exception as e:
        print(f"[경고] Fine-tuning 단계에서 예외 발생: {e}")

# ResNet 모델을 사용하여 훈련 데이터셋 이미지 특징 추출
print("ResNet 모델 기반 이미지 특징 추출 중...")

# transfer_model_resnet은 ResNet50 기반 전이 학습 모델입니다.
# 여기서는 지정한 중간 레이어(FEATURE_LAYER)의 출력을 특징으로 사용합니다.
try:
    feat_layer = base_model_resnet.get_layer(FEATURE_LAYER)
    chosen_layer_name = FEATURE_LAYER
except Exception:
    fallback = 'avg_pool'
    try:
        feat_layer = base_model_resnet.get_layer(fallback)
        chosen_layer_name = fallback
        print(f"[안내] FEATURE_LAYER='{FEATURE_LAYER}'를 찾지 못해 '{fallback}' 레이어로 대체합니다.")
    except Exception:
        feat_layer = None
        chosen_layer_name = 'model_output'
        print(f"[경고] '{FEATURE_LAYER}'와 'avg_pool' 레이어를 찾지 못해 모델 출력을 사용합니다.")

if feat_layer is not None:
    feature_model = Model(inputs=base_model_resnet.input, outputs=feat_layer.output)
else:
    feature_model = Model(inputs=base_model_resnet.input, outputs=base_model_resnet.output)

print(f"특징 추출 레이어: {chosen_layer_name}")
encoded_features_resnet = feature_model.predict(train_images_all)

print("ResNet 모델 기반 이미지 특징 추출 완료.")
print(f"추출된 특징 벡터 형태: {encoded_features_resnet.shape}")

# K-Means는 2차원 입력을 기대하므로, 추출된 특징 벡터를 Flatten합니다.
# pooling='avg'를 사용했기 때문에 이미 1차원 형태일 가능성이 높지만, 안전하게 reshape합니다.
if len(encoded_features_resnet.shape) > 2:
    encoded_features_resnet_flat = encoded_features_resnet.reshape(encoded_features_resnet.shape[0], -1)
else:
    encoded_features_resnet_flat = encoded_features_resnet

print(f"K-Means를 위한 ResNet 기반 Flatten된 특징 벡터 형태: {encoded_features_resnet_flat.shape}")

# ResNet 특징에 K-Means 클러스터링 적용
n_clusters = 2 # 강아지, 고양이 2개 클러스터
kmeans_resnet = KMeans(n_clusters=n_clusters, random_state=42, init='k-means++', n_init=KMEANS_N_INIT, max_iter=KMEANS_MAX_ITER)
print(f"ResNet 특징에 K-Means 클러스터링 수행 중 ({n_clusters}개 클러스터)...")

# encoded_features_resnet_flat는 이전 단계에서 준비했습니다.
kmeans_labels_resnet = kmeans_resnet.fit_predict(encoded_features_resnet_flat)

print("ResNet 특징에 K-Means 클러스터링 완료.")
print(f"생성된 클러스터 레이블 형태: {kmeans_labels_resnet.shape}")

# ResNet 특징 기반 K-Means 클러스터링 결과 평가
from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, homogeneity_score, completeness_score, v_measure_score, fowlkes_mallows_score

# 실제 레이블 (train_labels_all)과 KMeans 클러스터 레이블 (kmeans_labels_resnet) 비교
# train_labels_all은 데이터 로드 단계에서 준비했습니다.
# kmeans_labels_resnet는 이전 단계에서 생성했습니다.

print("\n--- ResNet 특징 기반 K-Means 클러스터링 평가 결과 (실제 레이블과 비교) ---")

# Adjusted Rand Index (ARI) 계산
ari_resnet = adjusted_rand_score(train_labels_all, kmeans_labels_resnet)
print(f"Adjusted Rand Index (ARI): {ari_resnet:.4f}")

# Normalized Mutual Information (NMI) 계산
nmi_resnet = normalized_mutual_info_score(train_labels_all, kmeans_labels_resnet)
print(f"Normalized Mutual Information (NMI): {nmi_resnet:.4f}")

# Homogeneity, Completeness, V-measure 계산
homogeneity_resnet = homogeneity_score(train_labels_all, kmeans_labels_resnet)
completeness_resnet = completeness_score(train_labels_all, kmeans_labels_resnet)
v_measure_resnet = v_measure_score(train_labels_all, kmeans_labels_resnet)
print(f"Homogeneity: {homogeneity_resnet:.4f}")
print(f"Completeness: {completeness_resnet:.4f}")
print(f"V-measure: {v_measure_resnet:.4f}")

# Fowlkes-Mallows Score 계산
fowlkes_mallows_resnet = fowlkes_mallows_score(train_labels_all, kmeans_labels_resnet)
print(f"Fowlkes-Mallows Score: {fowlkes_mallows_resnet:.4f}")


print("\nK-Means 클러스터링 결과와 실제 클래스 분포 확인 (참고):")
# 실제 클래스 레이블 가져오기 (ImageDataGenerator의 class_indices 사용)
# train_generator.class_indices는 {'Cat': 0, 'Dog': 1} 또는 그 반대 형태입니다.
class_labels = list(train_generator.class_indices.keys())
print(f"클래스 레이블: {class_labels}") # 예: ['Cat', 'Dog']

# KMeans 클러스터 0이 실제 어떤 클래스에 더 많이 해당하는지 확인
class_counts_in_cluster_0_resnet = {label: 0 for label in class_labels}
for i in range(len(kmeans_labels_resnet)):
    if kmeans_labels_resnet[i] == 0:
        actual_label_index = int(train_labels_all[i]) # 바이너리 클래스 모드 가정
        actual_label_name = class_labels[actual_label_index]
        class_counts_in_cluster_0_resnet[actual_label_name] += 1

print(f"K-Means 클러스터 0에 속한 이미지의 실제 클래스 분포: {class_counts_in_cluster_0_resnet}")

# KMeans 클러스터 1이 실제 어떤 클래스에 더 많이 해당하는지 확인
class_counts_in_cluster_1_resnet = {label: 0 for label in class_labels}
for i in range(len(kmeans_labels_resnet)):
    if kmeans_labels_resnet[i] == 1:
        actual_label_index = int(train_labels_all[i])
        actual_label_name = class_labels[actual_label_index]
        class_counts_in_cluster_1_resnet[actual_label_name] += 1

print(f"K-Means 클러스터 1에 속한 이미지의 실제 클래스 분포: {class_counts_in_cluster_1_resnet}")
